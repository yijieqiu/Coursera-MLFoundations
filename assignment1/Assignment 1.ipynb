{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Question 1](#q1)\n",
    "2. [Questions 2-5](#q2-5)\n",
    "3. [Questions 6-8](#q6-8)\n",
    "4. [Questions 9-12](#q9-12)\n",
    "5. [Questions 13-14](#q13-14)\n",
    "6. [Questions 15-17](#q15-17)\n",
    "7. [Questions 18-20](#q18-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 <a id=\"q1\" />\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q1.png\" alt=\"Question 1\" style=\"width: 500px;\"/>\n",
    "**Answer**: (ii), (iv), and (v)\n",
    "\n",
    "**Explanation**:\n",
    "  * (i) Prime numbers can be identified by definition with no ML involved\n",
    "  * (ii) Binary classification question\n",
    "  * (iii) Speed of falling object with respect to time can be calculated by applying Newton's Second Law and gravitational acceleration, with no ML involved.\n",
    "  * (iv) Learning optimal cycle based on inputs of cycle vs. traffic condition parameters\n",
    "  * (v) Learning recommended age basd on inputs of age vs. disease rate etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2-5 <a id=\"q2-5\" />\n",
    "#### Question 2\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q2.png\" alt=\"Question 2\" style=\"width: 500px;\"/>\n",
    "**Answer**: reinforcement learning\n",
    "\n",
    "**Explanation**: The task involves making improvements based on feedback.\n",
    "\n",
    "#### Question 3\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q3.png\" alt=\"Question 3\" style=\"width: 500px;\"/>\n",
    "**Answer**: unsupervised learning\n",
    "\n",
    "**Explanation**: Training inputs for the task contains no label for the target variable.\n",
    "\n",
    "#### Question 4\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q4.png\" alt=\"Question 4\" style=\"width: 500px;\"/>\n",
    "**Answer**: supervised learning\n",
    "\n",
    "**Explanation**: All target variables in training inputs have labels (face / no face)\n",
    "\n",
    "#### Question 5\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q5.png\" alt=\"Question 5\" style=\"width: 500px;\"/>\n",
    "**Answer**: active learning\n",
    "\n",
    "**Explanation**: The task involves *strategically* choosing data points to which model output is compared to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 6-8 <a id=\"q6-8\" />\n",
    "#### Question 6\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q6.png\" alt=\"Question 6\" style=\"width: 500px;\"/>\n",
    "**Answer**: ${\\frac{1}{L} \\times ( \\lfloor \\frac{N+L}{2} \\rfloor - \\lfloor \\frac{N}{2} \\rfloor )}$\n",
    "\n",
    "**Explanation**: OTS is determined by number of **even numbers** between $N$ and $N+L$. Floor vs. ceiling on casts an effect if the target number is **odd**. Test with the following cases and find the answer by elimination:\n",
    "    * N = 10 (even), L = 10, N+L=20(even), #even numbers = 5\n",
    "    * N = 10 (even), L = 11, N+L=21(odd), #even numbers = 5\n",
    "    * N = 11 (odd), L = 10, N+L=21(odd), #even numbers = 5\n",
    "\n",
    "#### Question 7\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q7.png\" alt=\"Question 7\" style=\"width: 500px;\"/>\n",
    "**Answer**: $2^L$\n",
    "\n",
    "**Explanation**: The complete sample size is $(N + L)$, but the target function $f$ only needs to perfectly predict the $N$ samples contained in $\\mathcal{D}$ in order to generate $\\mathcal{D}$ in noiseless setting. In other words, an instance of $f$ that generates $\\mathcal{D}$ can give *any*\n",
    "value for samples $N+1,N+2,...,N+L$. Since $y=\\{-1, +1\\}$ (2 possible values per sample $\\rightarrow$ 2x distinct target functions per additional sample), the total counts comes down to $2^L$\n",
    "\n",
    "#### Question 8\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q8.png\" alt=\"Question 8\" style=\"width: 500px;\"/>\n",
    "**Answer**: $\\mathbb{E}_f \\Bigl \\{E_{OTS}\\bigl(\\mathcal{A}_1(\\mathcal{D}), f\\bigr) \\Bigr \\}=\\mathbb{E}_f \\Bigl \\{E_{OTS}\\bigl(\\mathcal{A}_2(\\mathcal{D}), f\\bigr) \\Bigr \\}$\n",
    "\n",
    "**Explanation**:\n",
    "  * From Wikipedia: A deterministic algorithm is an algorithm which, given a *particular input*, will always produce the *same output*, with the underlying machine always passing through the *same sequence of states*.\n",
    "  * Recall from Question 7, that there can be $2^L$ target functions $f$ that generates $\\mathcal{D}$, but each $f$ can give different result for a given off-training-set (OTS) input. Therefore, the two hypothesis $\\mathcal{A}_1(\\mathcal{D})$ and $\\mathcal{A}_2(\\mathcal{D})$ can have different OTS when compared to a specific $f$. However, the expected OTS for both algorithms **across** the entire set of generative $f$ should be probably approximately equal given Hoeffding's Inequality, assuming sample size ($2^L$) is sufficently large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 9-12 <a id=\"q9-12\" />\n",
    "#### Question 9\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q9.png\" alt=\"Question 9\" style=\"width: 500px;\"/>\n",
    "**Answer**: 0.24\n",
    "\n",
    "**Explanation**:\n",
    "For the sample distribution $\\nu$ to equal that of population distribution $\\mu$ (0.5), 5 out of the 10 marbles must be orange. The probability of *any one of* such cases to occur is $0.5^5 \\times (1-0.5)^5$. Number of cases where 5 out of 10 marbles are orange is *10 choose 5*, or ${10 \\choose 5}$. Therefore, the total probability is ${10 \\choose 5} \\times 0.5^5 \\times (1-0.5)^5 = 0.246$\n",
    "\n",
    "#### Question 10\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q10.png\" alt=\"Question 10\" style=\"width: 500px;\"/>\n",
    "**Answer**: 0.39\n",
    "\n",
    "**Explanation**: Same logic as Question 9, just substitute in the new population distribution: ${10 \\choose 9} \\times 0.9^9 \\times (1-0.9)^1 = 0.387$\n",
    "\n",
    "#### Question 11\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q11.png\" alt=\"Question 11\" style=\"width: 500px;\"/>\n",
    "**Answer**: $9.1 \\times 10^{-9}$\n",
    "\n",
    "**Explanation**:\n",
    "  * Case 1: $\\nu = 0.1$, which gives probability ${10 \\choose 1} \\times (1-0.9)^9 \\times 0.9 = 9 \\times 10^{-9}$\n",
    "     * With $\\nu = 0.1$, only 1 out of 10 marbles is orange, which if modeled a single draw from population, has probability of 0.9\n",
    "     * Rest of the mables, given population distribution, each has 0.1 probability of not being orange. Assuming the marble draws are all iid, this portion of the probability is $0.1^9$\n",
    "     * Total number of such combinations is 10 choose 1, or ${10 \\choose 1}$\n",
    "  * Case 2: $\\nu = 0$, which gives probability $(1-0.9)^10 = 1 \\times 10^-10 = 0.1 \\times 10^{-9}$\n",
    "  * Combine probability of case 1 and case 2 gives $9.1 \\times 10^{-9}$\n",
    "\n",
    "#### Question 12\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q12.png\" alt=\"Question 12\" style=\"width: 500px;\"/>\n",
    "**Answer**: $5.52 \\times 10^{-6}$\n",
    "\n",
    "**Explanation**: $\\mu = 0.9, \\nu = 0.1 \\rightarrow \\epsilon = 0.8$, $N=10$, plug into Hoeffding's Inequality and get the probability as $2e^{-2\\epsilon^2N} = 2e^{-2\\times0.8^2\\times10}= 2e^{-12.8} = 5.52 \\times 10^{-6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 13-14 <a id=\"q13-14\" />\n",
    "#### Question 13\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q13.png\" alt=\"Question 13\" style=\"width: 500px;\"/>\n",
    "**Answer**: $\\frac{8}{256}$\n",
    "\n",
    "**Explanation**: Cases B and C gives orange 1's, thus the probabily of one randomly picked dice to have orange 1 is $\\frac{1}{2}$. The probability of getting 5 orange 1's in a draw is therefore $(\\frac{1}{2})^5 = \\frac{1}{32} = \\frac{8}{256}$\n",
    "\n",
    "#### Question 14\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q14.png\" alt=\"Question 14\" style=\"width: 500px;\"/>\n",
    "**Answer**: $\\frac{31}{256}$\n",
    "\n",
    "**Explanation**: The following types of dice must be drawn for a given number to be orange\n",
    "    * 1 : Dice type B or C\n",
    "    * 2 : Dice type A or C\n",
    "    * 3 : Dice type B or C\n",
    "    * 4 : Dice type A or D\n",
    "    * 5 : Dice type B or D\n",
    "    * 6 : Dice type A or D\n",
    "Therefore there are 4 unique combinations for getting orange numbers, (B, C), (A, C), (A, D), and (B, D). Each combination, as shown in Question 13, has probability $\\frac{8}{256}$.\n",
    "\n",
    "However, note that the cases where all 5 dices are of type A, B, C, or D are double-counted, so the actual probability is $4 \\times \\frac{8}{256} - \\frac{4}{1024} = \\frac{31}{256}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 15-17 <a id=\"q15-17\" />\n",
    "#### Question 15\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q15.png\" alt=\"Question 15\" style=\"width: 500px;\"/>\n",
    "**Answer**: 31-50 updates\n",
    "\n",
    "**Explanation**: See output below\n",
    "\n",
    "#### Question 16\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q16.png\" alt=\"Question 16\" style=\"width: 500px;\"/>\n",
    "**Answer**: 31-50 updates\n",
    "\n",
    "**Explanation**: See output below\n",
    "\n",
    "#### Question 17\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q17.png\" alt=\"Question 17\" style=\"width: 500px;\"/>\n",
    "**Answer**: 31-50 updates\n",
    "\n",
    "**Explanation**: See output below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Console output from running code for Questions 15-17\n",
    "\n",
    "```\n",
    "Reading training input file hw1_15_train.dat under path /Users/yijieqiu/Development/GitHub/coursera-ml-foundations/assignment1\n",
    "Question 15: Running PLA on training samples with update step 1 and no shuffling ...\n",
    "Number of iterations to PLA convergence: 37\n",
    "\n",
    "Question 16: Running PLA on training samples with update step 1 and shuffled input ...\n",
    "Average number of iterations for PLA to converge with update step 1 and shuffled input 34.5225\n",
    "\n",
    "Question 17: Running PLA on training samples with update step 0.5 and shuffled input ...\n",
    "Average number of iterations for PLA to converge with update step 0.5 and shuffled input 34.4815\n",
    "\n",
    "\n",
    "Process finished with exit code 0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 18-20 <a id=\"q18-20\" />\n",
    "#### Question 18\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q18.png\" alt=\"Question 18\"\n",
    "style=\"width: 500px;\"/>\n",
    "**Answer**: < 0.2\n",
    "\n",
    "**Explanation**: See output below\n",
    "\n",
    "#### Question 19\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q19.png\" alt=\"Question 19\"\n",
    "style=\"width: 500px;\"/>\n",
    "**Answer**: 0.2 - 0.4\n",
    "\n",
    "**Explanation**: See output below. The result demonstrates that pocket PLA indeed results in a more optimal hypothesis \n",
    "    than naive PLA, by checking for error rates before/after weight update.\n",
    "\n",
    "#### Question 20\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q20.png\" alt=\"Question 20\" style=\"width: 500px;\"/>\n",
    "**Answer**: < 0.2\n",
    "\n",
    "**Explanation**: See output below. The result demonstrates that allowing for more updates will indeed lead to a \n",
    "    better hypothesis with lower OTS error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Console output from running code for Questions 18-20\n",
    "```\n",
    "Reading training input file hw1_18_train.dat under path /Users/yijieqiu/Development/GitHub/coursera-ml-foundations/assignment1\n",
    "Reading training input file hw1_18_test.dat under path /Users/yijieqiu/Development/GitHub/coursera-ml-foundations/assignment1\n",
    "Question 18: Running 2000 trials ...\n",
    "Average OTS error rate of w_pocket obtaind after 50 updates : 0.14116099999999943\n",
    "\n",
    "Question 19: Running 2000 trials of pocket PLA on with update step 1, and max 50 updates ...\n",
    "Average OTS error rate of w: 0.2424500000000006\n",
    "\n",
    "Question 20: Running 2000 trials...\n",
    "Average OTS error rate of w_pocket obtained after 100 updates: 0.12482199999999988\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

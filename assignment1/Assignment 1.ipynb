{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Question 1](#q1)\n",
    "2. [Questions 2-5](#q2-5)\n",
    "3. [Questions 6-8](#q6-8)\n",
    "4. [Questions 9-12](#q9-12)\n",
    "5. [Questions 13-14](#q13-14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 <a name=\"q1\" />\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q1.png\" alt=\"Question 1\" style=\"width: 500px;\"/>\n",
    "**Answer**: (ii), (iv), and (v)\n",
    "\n",
    "**Explanation**:\n",
    "  * (i) Prime numbers can be identified by definition with no ML involved\n",
    "  * (ii) Binary classification question\n",
    "  * (iii) Speed of falling object with respect to time can be calculated by applying Newton's Second Law and gravitational acceleration, with no ML involved.\n",
    "  * (iv) Learning optimal cycle based on inputs of cycle vs. traffic condition parameters\n",
    "  * (v) Learning recommended age basd on inputs of age vs. disease rate etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2-5 <a name=\"q2-5\" />\n",
    "#### Question 2\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q2.png\" alt=\"Question 2\" style=\"width: 500px;\"/>\n",
    "**Answer**: reinforcement learning\n",
    "\n",
    "**Explanation**: The task involves making improvements based on feedback.\n",
    "\n",
    "#### Question 3\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q3.png\" alt=\"Question 3\" style=\"width: 500px;\"/>\n",
    "**Answer**: unsupervised learning\n",
    "\n",
    "**Explanation**: Training inputs for the task contains no label for the target variable.\n",
    "\n",
    "#### Question 4\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q4.png\" alt=\"Question 4\" style=\"width: 500px;\"/>\n",
    "**Answer**: supervised learning\n",
    "\n",
    "**Explanation**: All target variables in training inputs have labels (face / no face)\n",
    "\n",
    "#### Question 5\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q5.png\" alt=\"Question 5\" style=\"width: 500px;\"/>\n",
    "**Answer**: active learning\n",
    "\n",
    "**Explanation**: The task involves *strategically* choosing data points to which model output is compared to.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 6-8 <a name=\"q6-8\" />\n",
    "#### Question 6\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q6.png\" alt=\"Question 6\" style=\"width: 500px;\"/>\n",
    "**Answer**: ${\\frac{1}{L} \\times ( \\lfloor \\frac{N+L}{2} \\rfloor - \\lfloor \\frac{N}{2} \\rfloor )}$\n",
    "\n",
    "**Explanation**: OTS is determined by number of **even numbers** between $N$ and $N+L$. Floor vs. ceiling on casts an effect if the target number is **odd**. Test with the following cases and find the answer by elimination:\n",
    "    * N = 10 (even), L = 10, N+L=20(even), #even numbers = 5\n",
    "    * N = 10 (even), L = 11, N+L=21(odd), #even numbers = 5\n",
    "    * N = 11 (odd), L = 10, N+L=21(odd), #even numbers = 5\n",
    "\n",
    "#### Question 7\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q7.png\" alt=\"Question 7\" style=\"width: 500px;\"/>\n",
    "**Answer**: $2^L$\n",
    "\n",
    "**Explanation**: The complete sample size is $(N + L)$, but the target function $f$ only needs to perfectly predict the $N$ samples contained in $\\mathcal{D}$ in order to generate $\\mathcal{D}$ in noiseless setting. In other words, an instance of $f$ that generates $\\mathcal{D}$ can give *any*\n",
    "value for samples $N+1,N+2,...,N+L$. Since $y=\\{-1, +1\\}$ (2 possible values per sample $\\rightarrow$ 2x distinct target functions per additional sample), the total counts comes down to $2^L$\n",
    "\n",
    "#### Question 8\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q8.png\" alt=\"Question 8\" style=\"width: 500px;\"/>\n",
    "**Answer**: $\\mathbb{E}_f \\Bigl \\{E_{OTS}\\bigl(\\mathcal{A}_1(\\mathcal{D}), f\\bigr) \\Bigr \\}=\\mathbb{E}_f \\Bigl \\{E_{OTS}\\bigl(\\mathcal{A}_2(\\mathcal{D}), f\\bigr) \\Bigr \\}$\n",
    "\n",
    "**Explanation**:\n",
    "  * From Wikipedia: A deterministic algorithm is an algorithm which, given a *particular input*, will always produce the *same output*, with the underlying machine always passing through the *same sequence of states*.\n",
    "  * Recall from Question 7, that there can be $2^L$ target functions $f$ that generates $\\mathcal{D}$, but each $f$ can give different result for a given off-training-set (OTS) input. Therefore, the two hypothesis $\\mathcal{A}_1(\\mathcal{D})$ and $\\mathcal{A}_2(\\mathcal{D})$ can have different OTS when compared to a specific $f$. However, the expected OTS for both algorithms **across** the entire set of generative $f$ should be probably approximately equal given Hoeffding's Inequality, assuming sample size ($2^L$) is sufficently large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 9-12 <a name=\"q9-12\" />\n",
    "#### Question 9\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q9.png\" alt=\"Question 9\" style=\"width: 500px;\"/>\n",
    "**Answer**: 0.24\n",
    "\n",
    "**Explanation**:\n",
    "For the sample distribution $\\nu$ to equal that of population distribution $\\mu$ (0.5), 5 out of the 10 marbles must be orange. The probability of *any one of* such cases to occur is $0.5^5 \\times (1-0.5)^5$. Number of cases where 5 out of 10 marbles are orange is *10 choose 5*, or ${10 \\choose 5}$. Therefore, the total probability is ${10 \\choose 5} \\times 0.5^5 \\times (1-0.5)^5 = 0.246$\n",
    "\n",
    "#### Question 10\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q10.png\" alt=\"Question 10\" style=\"width: 500px;\"/>\n",
    "**Answer**: 0.39\n",
    "\n",
    "**Explanation**: Same logic as Question 9, just substitute in the new population distribution: ${10 \\choose 9} \\times 0.9^9 \\times (1-0.9)^1 = 0.387$\n",
    "\n",
    "#### Question 11\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q11.png\" alt=\"Question 11\" style=\"width: 500px;\"/>\n",
    "**Answer**: $9.1 \\times 10^{-9}$\n",
    "\n",
    "**Explanation**:\n",
    "  * Case 1: $\\nu = 0.1$, which gives probability ${10 \\choose 1} \\times (1-0.9)^9 \\times 0.9 = 9 \\times 10^{-9}$\n",
    "     * With $\\nu = 0.1$, only 1 out of 10 marbles is orange, which if modeled a single draw from population, has probability of 0.9\n",
    "     * Rest of the mables, given population distribution, each has 0.1 probability of not being orange. Assuming the marble draws are all iid, this portion of the probability is $0.1^9$\n",
    "     * Total number of such combinations is 10 choose 1, or ${10 \\choose 1}$\n",
    "  * Case 2: $\\nu = 0$, which gives probability $(1-0.9)^10 = 1 \\times 10^-10 = 0.1 \\times 10^{-9}$\n",
    "  * Combine probability of case 1 and case 2 gives $9.1 \\times 10^{-9}$\n",
    "\n",
    "#### Question 12\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q12.png\" alt=\"Question 12\" style=\"width: 500px;\"/>\n",
    "**Answer**: $5.52 \\times 10^{-6}$\n",
    "\n",
    "**Explanation**: $\\mu = 0.9, \\nu = 0.1 \\rightarrow \\epsilon = 0.8$, $N=10$, plug into Hoeffding's Inequality and get the probability as $2e^{-2\\epsilon^2N} = 2e^{-2\\times0.8^2\\times10}= 2e^{-12.8} = 5.52 \\times 10^{-6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 13-14 <a name=\"q13-14\" />\n",
    "#### Question 13\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q13.png\" alt=\"Question 13\" style=\"width: 500px;\"/>\n",
    "**Answer**: $\\frac{8}{256}$\n",
    "\n",
    "**Explanation**: Cases B and C gives orange 1's, thus the probabily of one randomly picked dice to have orange 1 is $\\frac{1}{2}$. The probability of getting 5 orange 1's in a draw is therefore $(\\frac{1}{2})^5 = \\frac{1}{32} = \\frac{8}{256}$\n",
    "\n",
    "#### Question 14\n",
    "<img src=\"https://github.com/yijieqiu/coursera-ml-foundations/raw/master/assignment1/q14.png\" alt=\"Question 14\" style=\"width: 500px;\"/>\n",
    "**Answer**: $\\frac{31}{256}$\n",
    "\n",
    "**Explanation**: The following types of dice must be drawn for a given number to be orange\n",
    "    * 1 : Dice type B or C\n",
    "    * 2 : Dice type A or C\n",
    "    * 3 : Dice type B or C\n",
    "    * 4 : Dice type A or D\n",
    "    * 5 : Dice type B or D\n",
    "    * 6 : Dice type A or D\n",
    "Therefore there are 4 unique combinations for getting orange numbers, (B, C), (A, C), (A, D), and (B, D). Each combination, as shown in Question 13, has probability $\\frac{8}{256}$.\n",
    "\n",
    "However, note that the cases where all 5 dices are of type A, B, C, or D are double-counted, so the actual probability is $4 \\times \\frac{8}{256} - \\frac{4}{1024} = \\frac{31}{256}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
